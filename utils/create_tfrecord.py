# -*- coding: utf-8 -*-
"""create_tfrecord.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ifQCFFwpghcfmfJV6Gl9r1oY3a36Wc5W

'''
Please prepare the raw image datas save to one folder,
makesure the path is match to the train_file/test_file.
'''
"""

# prompt: Mount Google Drivce

from google.colab import drive
drive.mount('/content/drive')

!pip install import_ipynb

# Commented out IPython magic to ensure Python compatibility.
# from tf_record import *
# %cd /content/drive/MyDrive/Colab Notebooks/create_tfrecords/
import import_ipynb
from tf_record import *

train_file = '/content/drive/MyDrive/Colab Notebooks/create_tfrecords/dataset/r3d_train_temp2.txt'

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/create_tfrecords/
# %run tf_record.ipynb
# %cd dataset/

if __name__ == '__main__':
	# write to TFRecord
	train_paths = open(train_file, 'r').read().splitlines()

  # test_paths = open(test_file, 'r').read().splitlines()

	# write_record(train_paths, name='../dataset/jp_train.tfrecords')
	# write_record(test_paths, name='../dataset/newyork_test.tfrecords')

	# write_seg_record(train_paths, name='../dataset/jp_seg_train.tfrecords')
	# write_seg_record(train_paths, name='../dataset/newyork_seg_train.tfrecords')

	write_bd_rm_record(train_paths, name='../dataset/newyork_train2.tfrecords')
	# write_bd_rm_record(train_paths, name='../dataset/all_train3.tfrecords')

	# read from TFRecord
	# loader_list = read_record('../dataset/jp_train.tfrecords')
	# loader_list = read_seg_record('../dataset/jp_seg_train.tfrecords')

	# loader_list = read_bd_rm_record('../dataset/newyork_bd_rm_train.tfrecords')
	# loader_list = read_bd_rm_record('../dataset/jp_bd_rm_train.tfrecords')

	# images = loader_list['images']
	# bd_ind = loader_list['label_boundaries']
	# rm_ind = loader_list['label_rooms']

	# with tf.Session() as sess:
	# 	# init all variables in graph
	# 	sess.run(tf.group(tf.global_variables_initializer(),
	# 					tf.local_variables_initializer()))

	# 	coord = tf.train.Coordinator()
	# 	threads = tf.train.start_queue_runners(sess=sess, coord=coord)

	# 	image, bd, rm = sess.run([images, bd_ind, rm_ind])

	# 	print 'sess run image shape = ',image.shape
	# 	print 'sess run wall shape = ', bd.shape
	# 	print 'sess run room shape =', rm.shape

	# 	bd = np.argmax(np.squeeze(bd), axis=-1)
	# 	rm = np.argmax(np.squeeze(rm), axis=-1)
	# 	plt.subplot(231)
	# 	plt.imshow(np.squeeze(image))
	# 	plt.subplot(233)
	# 	plt.imshow(bd)
	# 	plt.subplot(234)
	# 	plt.imshow(rm)
	# 	plt.show()

	# 	coord.request_stop()
	# 	coord.join(threads)
	# 	sess.close()

import tensorflow as tf
import matplotlib.pyplot as plt

# Enable interactive mode in Matplotlib
plt.ion()

tfrecord_file = '/content/drive/MyDrive/Colab Notebooks/create_tfrecords/dataset/newyork_train2.tfrecords'

feature_description = {
    'image': tf.io.FixedLenFeature([], tf.string),
    'boundary': tf.io.FixedLenFeature([], tf.string),
    'room': tf.io.FixedLenFeature([], tf.string),
    'door': tf.io.FixedLenFeature([], tf.string)
}

def _parse_function(example_proto):
    return tf.io.parse_single_example(example_proto, feature_description)

dataset = tf.data.TFRecordDataset(tfrecord_file)
parsed_dataset = dataset.map(_parse_function)

example_list = list(parsed_dataset)

# Display images using Matplotlib's interactive mode
for example in example_list:
    image_data = tf.io.decode_raw(example['image'], tf.uint8)
    boundary_data = tf.io.decode_raw(example['boundary'], tf.uint8)
    room_data = tf.io.decode_raw(example['room'], tf.uint8)
    door_data = tf.io.decode_raw(example['door'], tf.uint8)

    image_shape = [512, 512, 3]
    bd_shape = [512, 512, 1]
    rm_shape = [512, 512, 1]
    dr_shape = [512, 512, 1]

    img_data = tf.reshape(image_data, image_shape)
    bd_data = tf.reshape(boundary_data, bd_shape)
    rm_data = tf.reshape(room_data, rm_shape)
    dr_data = tf.reshape(door_data, dr_shape)

    # Display images using Matplotlib
    plt.imshow(img_data.numpy())
    plt.show()
    plt.imshow(bd_data.numpy())
    plt.show()
    plt.imshow(rm_data.numpy())
    plt.show()
    plt.imshow(dr_data.numpy())
    plt.show()

# Disable interactive mode to ensure plots are displayed properly
plt.ioff()
plt.show()

ls

"""
# Output tfrecord data.

Hmm.. What's wrong."""

import tensorflow as tf

tfrecord_file = '/content/drive/MyDrive/Colab Notebooks/create_tfrecords/dataset/newyork_train2.tfrecords'

feature_description = {
    'image': tf.io.FixedLenFeature([], tf.string),
    'boundary': tf.io.FixedLenFeature([], tf.string),
    'room': tf.io.FixedLenFeature([], tf.string),
    'door': tf.io.FixedLenFeature([], tf.string)
}

def _parse_function(example_proto):
    return tf.io.parse_single_example(example_proto, feature_description)

dataset = tf.data.TFRecordDataset(tfrecord_file)
parsed_dataset = dataset.map(_parse_function)

example_list = []

for example in parsed_dataset:
  image_data = tf.io.decode_raw(example['image'], tf.uint8)
  boundary_data = tf.io.decode_raw(example['boundary'], tf.uint8)
  room_data = tf.io.decode_raw(example['room'], tf.uint8)
  door_data = tf.io.decode_raw(example['door'], tf.uint8)

  image_shape = [512,512,3]
  bd_shape = [512,512,1]
  rm_shape = [512,512,1]
  dr_shape = [512,512,1]

  img_data = tf.reshape(image_data,image_shape)
  bd_data = tf.reshape(boundary_data, bd_shape)
  rm_data = tf.reshape(room_data, rm_shape)
  dr_data = tf.reshape(door_data, dr_shape)

  example_list.append([img_data, bd_data, rm_data, dr_data])

rows, cols = len(example_list), 4

fig, axs = plt.subplots(rows, cols, figsize=(15, 15))

for i, example in enumerate(example_list):

    img, bd, rm, dr = example
    axs[i, 0].imshow(img.numpy())
    axs[i, 1].imshow(bd.numpy())
    axs[i, 2].imshow(rm.numpy())
    axs[i, 3].imshow(dr.numpy())

    for j in range(cols):
        axs[i, j].axis('off')

plt.show()

